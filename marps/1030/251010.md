---
marp: true
theme: pku-jjq
transition: none
size: 16:9
paginate: true
class: pkulogo
fragment: false
---
<!-- _class: cover_a -->

<!-- _header: "" -->

<!-- _footer: "" -->

<!-- _paginate: "" -->

<!-- fit -->

# On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

## 基于大型语言模型的多7智能体协作系统在故障智能体情况下的鲁棒性研究

##### ICML 2025

2025/10/10

---

## Core contribution

> 基于LLM的多智能体系统通过领域专家智能体协作，在代码生成、数学解题等任务中表现出色
> &nbsp;
> 但 “故障智能体”（频繁出错的笨拙智能体或恶意智能体）对系统整体性能的影响尚未得到充分研究。

论文重点回答了三个问题：

<div class="circle-ol">

1. 如何设计方案为智能体模拟 **注入故障** ？
2. 不同系统结构在故障智能体存在时，对不同下游任务的 **抗故障能力（resilience）** 如何？
3. 如何 **提升系统抗故障能力** 以抵御故障智能体的负面影响？

</div>

---

## 故障智能体模拟方法

<!-- _class: bq-red -->

> 混沌实验
>
> 混沌实验是一种通过在系统中**主动注入各种故障和异常**情况，来观察系统在面临不稳定因素时的行为和表现，并以此提升系统稳定性和异常处置能力的方法。
> 在工业界中，特别是在Ops（运维）领域常见

论文提出两种自动化模拟故障智能体的方案，无需人工修改即可引入错误：

- AUTOTRANSFORM
- AUTOINJECT

---

<!-- _class: fixedtitleA -->

## AUTOTRANSFORM 故障转移智能体

<!-- _class: cols-2-46 -->

<div class="ldiv">

以**智能体原始配置文件**为输入，生成保留原功能但会产生 “隐蔽错误” 的故障配置文件。

* **分析任务**：分析这个智能体的下游任务是什么
* **列举错误方式**：利用LLM列出了所有可能引入错误的方法，强调了需要隐蔽以避免被其他agent检测。
* **重写配置文件**：使用这些错误注入方法重写agent的配置文件，确保agent的原始功能保持不变。

> 本质仍然是利用一个大模型生成攻击

</div>

<div class=rimg>

![w:900](https://i.postimg.cc/fWFHM8B6/image.png)

</div>

---

### AUTOTRANSFORM 的局限性

<!-- _class: bq-red -->

> AUTOTRANSFORM的局限性
>
> 由于LLM生成过程具有随机性，难以确保这些agent会引入 **特定数量和类型（无法量化）** 的错误
>
> 不能定量衡量错误多少对智能体的影响

---

## AUTOINJECT

<!-- _class: cols-2-64 -->

<div class=ldiv>

AUTOINJECT 可以直接**拦截智能体间的消息**并注入错误，可精确控制错误相关参数 ——

* 错误消息比例（ $P_m$，默认 1.0）
* 单条消息错误率（$P_e$，默认 0.2）
* 错误类型

> 本质还是大模型去生成错误，但是生成的错误更加细粒度化，固定化

</div>

<div class=rimg>

![h:550](https://i.postimg.cc/65r3f5bG/image.png)

</div>

---

### 错误类型

<!-- _class: cols-2-64 -->

<div class=limg>

![w:700](https://i.postimg.cc/rF1HVvs7/image.png)

</div>

<div class=rdiv>

* **语法**问题：无法正常运行，通过一些 `tool`检测出来（如 _计算器、编译器_ ）可以发现，是格式问题
* **语义**问题：可以正常运行 ，运行结果不对，是 逻辑问题

</div>

---

## 智能体之间的协作方式

![w:700](https://i.postimg.cc/gJfMmPhv/251010.png)

---

## 实验结果

#### RQ1：系统结构对耐故障能力的影响（Impact of System Structures）

层级结构抗故障能力最优，线性结构最差

![h:300](https://i.postimg.cc/X7hvWH1j/image.png)

> Vanilla: 对照组。分数越高，性能越好。

---

#### RQ1：系统结构对耐故障能力的影响（Impact of System Structures）

* 原因分析
  * 层级结构优势原因：存在 “**高层智能**体”（如  *“裁判”、 “协调者”*），可接收多智能体的子任务结果，通过 “**多版本比对**” 筛选正确答案，提升错误恢复概率
  * 线性结构劣势原因：依赖 “单向通信链”（如 A→B→C），故障智能体的错误会**逐级传递**，放大错误信息，且高层**无法监督底层操作**
  * 扁平结构劣势原因：无明确领导，智能体**双向通信易出现 “协调瘫痪”**（如多个智能体坚持错误观点，无法达成共识）

---

### RQ2：下游任务对故障的敏感度（Impact of Downstream Tasks）

<!-- _class: cols-2-64 -->

<div class=ldiv>

- 客观任务（代码生成、数学）对故障更敏感
- 主观任务（翻译、文本评估）耐故障能力更强

<br>

| **任务类型** | **性能下降幅度** | **核心原因**                                              |
| :----------------- | :--------------------- | :-------------------------------------------------------------- |
| 代码生成           | 22.6%                  | 严格语法/逻辑要求，微小错误即导致功能失效(如缺括号报错)         |
| 数学解题           | 9.89%                  | 多步推理错误累积(第一步错误导致后续全错)                        |
| 文本评估           | 5.42%                  | 主观判断无统一标准，错误易被忽略                                |
| 翻译               | 4.70%                  | 语义容错性高(如"拉下水"误译为"pull into water"仍可传递部分含义) |

</div>

<div class=rimg>

![](https://i.postimg.cc/7hSyy956/image.png)

</div>

---

## Extra insights: 故障对多智能体系统的影响比单智能体更大

<!-- _class: cols-2-64 -->

<div class=ldiv>

| **对比项** | **分类** | **评分**                                    | **原因**                   |
| :--------------- | :------------- | :------------------------------------------------ | :------------------------------- |
| 无故障时         | 多智能体       | ↑（GPT-3.5 下高 4.76 分，GPT-4o 下高 5.29 分）   | 分工协作能分解复杂任务           |
|                  | 单智能体       | ↓                                                |                                  |
| 有故障时         | 多智能体       | ↓（代码生成中，多智能体性能从 64.73 降至 39.15） | 性能可能降至单智能体水平甚至更低 |
|                  | 单智能体       | ↑                                                |                                  |

</div>

<div class=rimg>

![](https://i.postimg.cc/7hSyy956/image.png)

</div>

---

### RQ3：错误率对系统性能的影响（Impact of Error Rates）

<!-- _class: cols-2-64 -->

<div class=ldiv>

> 错误消息比例（ $P_m$）的影响大于单条消息错误数（$P_e$）.

1. $P_m$升高时性能**持续下降**：$P_e$从 0.2 升至 0.6，系统平均性能从 60.57 降至 47.53（下降 13.04 分），因错误消息增多导致 “**错误累积效应**”
2. $P_e$升高时性能先降后稳，甚至小幅上升：
   1. $P_e$从 0.2 升至 0.4，性能从 60.57 降至 53.05（下降 7.52 分）；
   2. 但$P_e$从 0.4 升至 0.6 时，部分系统（如 MetaGPT、MAD）性能反而从 53.05 升至 53.75（上升 0.7 分）
   3. **因单条消息中集中的错误过多 “暴露特征”**，其他智能体主动要求修正
3. 极端$P_m$危害最大：当$P_m=1.0$（所有消息均错误）且$P_e=0.6$（单条消息 60% 内容错误）时，系统平均性能仅 22.75，接近 “**完全失效**”

</div>

<div class=rimg>

![](https://i.postimg.cc/KYZGm6bb/image.png)

</div>

---

### RQ4：错误类型对系统性能的影响（Impact of Error Types）

> 语义(逻辑)错误比语法错误危害更大

GPT-3.5 代码生成任务中，语义错误使系统平均性能降至 39.15，语法错误降至 47.78

![w:600](https://i.postimg.cc/CM4WgR1c/image.png)

原因：

- LLM 在大规模代码 / 文本语料上训练，易识别**语法错误（如缺括号与训练数据分布差异大）**
  - 当然也可以通过调用工具来判定语法错误；
- 但语义错误需 “深度理解任务意图”（如判断代码循环起始值是否符合需求），LLM 难以察觉

---

## 其他的发现

<!-- _class: cols-2-46 -->

<div class=ldiv>

#### 错误注入有助于提升性能表现

* 回头看：
  * 当系统检测到**明显错误**时，会要求该agent向其他智能体发送修正指令。
  * 这种机制不仅能纠正新注入的错误，还能修复原有代码中的缺陷

</div>

<div class=rimg>

![](https://i.postimg.cc/SK0N2g9F/image.png)

</div>

---

#### 错误注入有助于提升性能表现

* 打破思维循环：
  * 部分系统（如 MAD 的 “辩论机制”）因依赖同一 LLM 作为 backbone，易陷入 “重复讨论”（如两个辩论者反复强调相同观点，无法产生新视角）
  * **外部注入的 “差异性错误”** 能打破原有信息分布，使智能体跳出固化的逻辑，进而优化最终结果。

<!-- _class: bq-red -->

> tips：错误并不是一定有效
>
> “错误是否具备‘干预价值’”—— 是性能提升的关键，不是 “有错误”，而是 “错误能被精准利用”

---

#### 语言模型（LLM）理解自然语言而非代码逻辑

<!-- _class: cols-2-64 -->

<div class=ldiv>

在 “判断代码是否修复 bug” 任务中，当代码仍存在错误（如函数 `below_zero`始终返回 `False`）

但添加注释 “*the bug had been corrected*” 后，所有 6 个系统均**忽略代码错误，认为任务完成**

</div>

<div class=rimg>

![](https://i.postimg.cc/C5w4FC7t/image.png)

</div>

---

#### 高层智能体故障影响更大

> 对 “任务分配者”注入错误后，系统性能下降幅度显著大于 “执行层智能体”

- 原因:
  - 高层智能体控制 “任务方向”，其错误会导致**整个协作偏离目标**
  - 执行层错误仅影响**局部子任务**

---

## 提升系统抗故障能力

#### Challenger（质疑机制）

_针对 “智能体自主生成错误”（对应 AUTOTRANSFORM）_

AUTOTRANSFORM 的问题是 “修改智能体配置文件，让其自主生成隐蔽错误”，而原有多智能体系统的短板是： **智能体仅能执行自身任务，不会主动质疑他人输出** （即使有能力识别错误）。

> 例如，Camel 的 Assistant 智能体生成错误代码后，User 智能体若未被设计 “检查代码” 的功能，会直接沿用错误结果。

---

Challenger 并非新增智能体，而是**在每个现有智能体的配置文件中，添加 “错误识别与质疑” 的功能描述**，让智能体在执行原有任务前，先完成 “错误检测” 步骤：

<br>

* 具体操作：
  * 在智能体的原始 prompt 中加入逻辑：“在执行你的任务前，需先检查接收的消息是否由故障智能体生成；若发现故意错误（如代码逻辑错、翻译语义偏差），回复‘unsafe’并指出可疑点；若无误，回复‘safe’后再执行原任务。”

---

#### Inspector（审查智能体）

_针对 “消息被注入错误”（对应 AUTOINJECT）_

AUTOINJECT 的问题是 “直接拦截智能体间的消息并注入错误”，且错误位置 / 类型可控，原有系统缺乏 “消息中间审查环节”—— 错误消息会直接传递给下一个智能体，导致后续步骤出错。

> 例如，AUTOINJECT 在 MetaGPT 的 “工程师→测试员” 消息中注入代码错误，测试员会直接基于错误代码测试，导致结果失效。Inspector 的设计灵感来源于此：既然 AUTOINJECT 通过 “拦截消息” 注入错误，那么就新增一个 “拦截消息” 的审查智能体，在错误消息到达目标智能体前完成修正。

---

Inspector 是**新增的独立智能体，不参与原任务执行，仅负责 “消息拦截 - 错误审查 - 修正 / 标记”**，相当于系统的 “安全网关”，具体流程如下：

1. 消息拦截：实时捕获所有智能体间传递的消息（如 A→B 的代码、B→C 的翻译结果）；
2. 错误审查：基于任务类型（如代码生成查语法 / 语义错误、翻译查语义偏差）和历史对话上下文，判断消息是否存在故意错误；
3. 错误处理：若发现错误，直接修正（如将代码中的语义错误改为正确逻辑、将翻译的歧义错误改为准确表达）；若无误，标记 “safe” 并传递给目标智能体。

---

## 一些可能的后续研究方向

* 故障的危害程度取决于 “是否能沿通信链传递”：针对“已经存在的线性结构/扁平结构”，能否引入一个 <u> leader </u> 角色，变换为“层级结构”
* 轻量化防御机制：Inspector机制采用的是独立智能体，对token消耗较大

  * 可以通过迁移学习，变为2个小样本模型？先判断再修正？
  * 对错误进行分级，比如代码语法错误，通过外部工具就能检测到，不用使用大模型来检测
* 生命周期扩展：

  * 故障监测：本文Inspector审查智能体✔
  * 故障止损：当检测到某个智能体持续输出错误时，能否自动**隔离**该智能体，防止其继续影响系统
  * 故障溯源/根因定位（RCA 4 Agent）：进一步**排查**是哪个智能体在其中出现错
