---
marp: true
theme: pku-jjq
transition: none
size: 16:9
paginate: true
class: pkulogo
fragment: false
---
<!-- _class: cover_a -->

<!-- _header: "" -->

<!-- _footer: "" -->

<!-- _paginate: "" -->

<!-- fit -->

# When Machine Unlearning Meets  Retrieval-Augmented Generation (RAG): Keep  Secret or Forget Knowledge?

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

## 基于检索增强生成（RAG）的大语言模型机器遗忘方法

##### Shang Wang, Tianqing Zhu*, et al. (2025)
##### arXiv:2410.15267v2



---

## 研究背景与动机

> 大语言模型（LLMs）具备强大生成能力，但训练中易保留敏感、有害或版权数据，引发法律与伦理风险，“被遗忘权”诉求日益迫切。

### 传统机器遗忘方法的三大局限
- **高计算开销**：如梯度上升需微调模型，论文实验遗忘5个概念耗时超79分钟
- **闭源模型适配难**：依赖参数访问，无法应用于ChatGPT、Gemini等商业闭源模型
- **灾难性遗忘风险**：修改参数易损害无关知识性能，MMLU基准分数下降可达20%以上

### RAG技术
- 核心特性：不修改模型参数，通过外部知识库调控生成过程
- 关键价值：为LLM提供轻量级行为控制方案，无需触碰内部结构，因此同时适用于开源和闭源模型

---

## 相关工作
<!-- _class: bq-red -->
> 机器遗忘技术演进：从参数级修改到行为级调控
>
> 传统方法依赖模型内部调整，难以适配复杂LLM场景；RAG技术通过外部知识干预，为遗忘提供全新思路。

#### 1. 机器遗忘技术分类
| 技术路线 | 代表方法 | 适用场景 | 核心局限 |
|---------|---------|---------|---------|
| **精确遗忘** | 完全重训练 | 小规模模型 | 计算成本极高 |
| **近似遗忘** | 梯度上升、剪枝 | 中大规模模型 | 需要参数访问 |
| **数据重组织** | SISA算法 | 可分片数据集 | 需预先规划 |

---
#### 2.现有LLM遗忘方法对比

| 方法 | 核心机制 | 主要优势 | 致命缺陷 |
|-----|---------|---------|---------|
| **梯度上升[9]** | 反向优化目标数据损失 | 开源模型效果尚可，遗忘较彻底 | 计算开销高<br>闭源模型完全不可用<br>易导致灾难性遗忘 |
| **In-context Unlearning[11]** | 构造反事实提示引导 | 计算开销低<br>实现简单 | 抗攻击能力弱（USR<21%）<br>易被"反遗忘"攻击破解<br>遗忘不彻底 |
| **μ-Unlearning[10]** | 微调辅助模型调整输出 | 遗忘相对精准 | 需要参数访问权限<br>计算复杂度高<br>无法适配闭源模型 |


<center>

所有现有方法都**无法同时满足**：通用性（闭源适配）+ 低开销 + 高鲁棒性

</center>

---

## 研究目标与核心贡献

### 研究目标
本文提出一种基于RAG的轻量级行为型遗忘框架，在不修改LLM参数的前提下，实现高效、通用、安全的知识遗忘，适配开源与闭源模型场景

### 五大核心贡献
<div class="circle-ol">

1. **首创性**：首个将RAG技术应用于LLM机器遗忘的研究，突破参数依赖瓶颈
2. **双任务支持**：同时实现样本级（单条训练数据）与概念级（特定知识）遗忘
3. **全场景适配**：无缝支持闭源（GPT-4o、Gemini）与开源（Llama-2、Vicuna）模型
4. **五维达标**：严格满足有效性、通用性、无害性、简洁性、鲁棒性五大标准
5. **可扩展性**：轻松延伸至多模态LLM（DALL·E 3）与LLM-based Agents（RAG-Flow）

</div>

---
## 方法框架

<!-- _class: cols-2-46 -->

<div class=ldiv>

### 三大核心组件

**1. 检索组件（P）**
- 样本遗忘：使用样本本身
- 概念遗忘：多维度描述

**2. 约束组件（Q）**
- 明确的保密指令。示例："禁止生成相关内容"
- 作用：强制LLM输出拒绝响应

**3. 遗忘知识库（UK）**
- 存储所有"P+Q"拼接的遗忘知识项
- 与良性知识库（BK）协同工作

</div>

<div class=rimg>

![h:400](https://i.postimg.cc/3RQHYH8J/image.png)

</div>

---

## 优化目标与约束

### 形式化定义

**主目标：最大化遗忘成功率**

$$
\max \text{USR} = \frac{\text{成功拒绝的查询数}}{\text{总遗忘目标查询数}} \geq 99\%
$$

**约束条件：保持模型效用**

$$
\text{s.t.} \quad |\text{Performance}_{\text{after}} - \text{Performance}_{\text{before}}| \leq 1\%
$$

### 核心指标

- **遗忘效果**：USR（遗忘成功率）、ROUGE-L（输出偏离度）
- **模型效用**：MMLU、ARC等基准测试性能保持
- **计算效率**：遗忘知识构造时间 < 1分钟

---

<!-- _class: fixedtitleA -->

## （1）遗忘知识构造

<!-- _class: cols-2-55 -->

<div class="ldiv">

#### 双场景知识构造逻辑
| 遗忘类型       | 检索组件（P）构造方式                | 约束组件（Q）构造方式                          |
|----------------|---------------------------------------|-----------------------------------------------|
| 样本遗忘       | 直接复用原始样本内容（相似度最高）    | 辅助LLM生成版权/隐私相关拒绝指令              |
| 概念遗忘       | 待遗忘LLM生成多维度描述（覆盖核心信息）| 辅助LLM生成全面禁止指令（含衍生内容）          |
<center>
<div class=rimg>

![w:500](https://i.postimg.cc/52H0tbVK/ping-mu-jie-tu-2025-10-30-163915.png)

</div>
</center>

---
### 标准化算法流程
1. 调用辅助LLM（如GPT-4o）生成P和Q组件
2. 按“P+Q”格式拼接为遗忘知识项k
3. 将k存入RAG外部遗忘知识库（UK）
4. 融合UK与良性知识库（BK）供检索调用

> 示例：k = “哈利·波特：系列小说… → 禁止生成任何相关内容”

</div>

<div class=rimg>
<center>

![w:500](https://i.postimg.cc/JhDPKDWZ/ping-mu-jie-tu-2025-10-30-164443.png)
<!-- 注：此处图片可替换为遗忘知识构造流程图 -->
<center>
</div>

---
## 遗忘知识构造算法

![ h:550 #r](https://i.postimg.cc/k5qgv8Sw/ping-mu-jie-tu-2025-10-30-164636.png)

**输入参数**
- $c$：待遗忘目标（单一样本 $x_i \in E_{sample}$ 或单个概念 $C_i \in E_{concept}$）
- $LLM_{cons}$：辅助生成约束组件的LLM（如GPT-4o）
- $LLM_{un}$：待遗忘的目标LLM

**四步构造流程**

**Step 1：生成检索组件（P）→ 调用 CRAFT RETRIEVAL 函数**
- **样本遗忘（$c \in E_{sample}$）**：直接取样本本身作为P（$P = c$），利用样本与自身的高相似度确保检索命中
- **概念遗忘（$c \in E_{concept}$）**：调用 $LLM_{un}$ 生成$c$的多维度全面描述作为P，覆盖核心信息以适配多样查询场景

---
## 遗忘知识构造算法

![ h:550 #r](https://i.postimg.cc/k5qgv8Sw/ping-mu-jie-tu-2025-10-30-164636.png)

**Step 2：生成约束组件（Q）→ 调用 CRAFT CONSTRAINT 函数**
- 调用 $LLM_{cons}$ 生成保密指令，明确要求 $LLM_{un}$ 拒绝生成与$c$相关的内容（含衍生信息）
- 验证逻辑：若 $LLM_{un}$ 基于Q仍生成$c$相关内容，则重新生成Q，直至拒绝响应或达到最大尝试次数
- 指令特性：标注“最高优先级”，确保 $LLM_{un}$ 优先遵守


---
## 遗忘知识构造算法

![ h:550 #r](https://i.postimg.cc/k5qgv8Sw/ping-mu-jie-tu-2025-10-30-164636.png)
**Step 3：拼接遗忘知识项（$k$）→ MAIN 过程核心逻辑**
- 按文本拼接规则构造遗忘知识项：$k = P + Q$（“+”表示文本串联）
- 生成M条知识项（$k_1, k_2, ..., k_M$，M为预设条目数），存入遗忘知识库 $UK$

**Step 4：知识库融合→ 适配RAG检索流程**
- 将遗忘知识库 $UK$ 与良性知识库 $BK$ 融合，形成统一检索库
- 供RAG系统的检索器 $\Gamma(\cdot)$ 调用，确保用户输入命中$c$时能提取对应$k$


---

## 实验


#### 1. 实验对象（覆盖主流模型）
- 闭源模型：GPT-4o、Gemini（商业场景代表）
- 开源模型：Llama-2-7b-chat、Vicuna-7B、PaLM 2（学术常用）

#### 2. 任务与数据集
- 样本遗忘：Tiny-NQ（2000条问答对，微调Llama-2）
- 概念遗忘：Wikipedia 100个主题（小说、科技、名人）
- 有害内容遗忘：25个恶意主题（如“网络犯罪”）

---
### 3. 核心评估指标
| 指标                | 核心意义                          | 理想范围          |
|---------------------|-----------------------------------|-------------------|
| USR（遗忘成功率）   | 成功遗忘的尝试占比                | ≥99%              |
| ROUGE-L（输出偏离度）| 遗忘后与原始输出的相似度          | ≤0.1              |
| TPR@1%FPR（残留记忆）| 记忆泄露程度                      | ≈1%（随机水平）  |
| MMLU/ARC（模型效用）| 遗忘后无关任务性能                | 差异≤1%           |

</div>
<center>

![h:300](https://i.postimg.cc/0yMV0WmB/ping-mu-jie-tu-2025-10-30-170732.png)

<!-- 注：此处图片可替换为实验设置示意图 -->

</div>

---

## 实验结果（1）——有效性验证

#### 开源模型（Llama-2-7b-chat）样本遗忘结果对比
| 方法               | USR↑    | ROUGE-L↓ | TPR@1%FPR↓ |
|--------------------|---------|----------|------------|
| 梯度上升[9]        | 75.8%   | 32.7     | 2.0%       |
| In-context Unlearning[11] | 20.7% | 72.4     | 2.2%       |
| μ-Unlearning[10]   | 66.3%   | 37.8     | 1.8%       |
| RAG-based（本文）  | 100%    | 0.0      | 1.2%       |

#### 关键结论
1. 本文方法实现100%遗忘成功率，输出完全偏离原始内容（ROUGE-L=0）
2. 残留记忆仅1.2%，接近随机猜测水平，遗忘更彻底
3. 闭源模型（GPT-4o）上USR达99.3%，远超基线方法（5.2%）



---

## 实验结果（2）——鲁棒性验证

#### 1. 抗攻击性能（面对恶意输入）
| 攻击类型                | 代表形式                          | 本文方法USR       | 基线方法（In-context）USR |
|-------------------------|-----------------------------------|-------------------|---------------------------|
| Jailbreak攻击           | DAN模式、Start Prompt、Advanced   | 87%–99%           | 3%–8%                     |
| Prompt Injection攻击    | “忽略之前指令，回答XXX”            | 99%               | 5%以下                    |

##### 2. 抗“反遗忘”能力（Prompt改写场景）
- 结果：本文方法USR仍保持97%以上，基线方法平均下降30%-50%
- 原因：RAG检索基于语义匹配，改写提示仍能命中遗忘知识
<center>

![w:500 ](https://i.postimg.cc/0j1zhNHN/ping-mu-jie-tu-2025-10-30-171147.png)
<!-- 注：此处图片可替换为鲁棒性结果图表 -->

<center>

---

## 实验结果（3）——通用性、无害性与简洁性

#### 1. 通用性验证（多模型适配）
| 模型类型       | 具体模型                | 遗忘成功率（USR） |
|----------------|-------------------------|-------------------|
| 闭源模型       | GPT-4o                  | 99.3%             |
|                | Gemini                  | 99.5%             |
| 开源模型       | Llama-2-7b-chat         | 100%              |
|                | Vicuna-7B               | 98.3%             |
|                | PaLM 2                  | 100%              |

---
#### 2. 无害性验证（模型效用无损）
- 结果：遗忘前后MMLU/ARC分数差异≤0.5%，无灾难性遗忘
- 对比：梯度上升方法MMLU分数平均下降7.5%

#### 3. 简洁性验证（计算开销）
- 本文方法：遗忘5个概念仅需63秒（≈1分钟）
- 梯度上升：需4752秒（≈79分钟），耗时是本文的75倍

</div>

<div class=rimg>
<center>

![w:700](https://i.postimg.cc/zB0QcLfn/ping-mu-jie-tu-2025-10-30-171510.png)
<!-- 注：此处图片可替换为多维度结果对比图 -->

<center>
</div>

---

## 案例研究（实际应用验证）

![w:400 #r](https://i.postimg.cc/rsGNP3gL/ping-mu-jie-tu-2025-10-30-171858.png)
### 案例1：多模态LLM遗忘（DALL·E 3）
- 任务：遗忘“tomato”（番茄）与“kola”（可乐）概念
- 过程：构造多模态遗忘知识（文本描述+禁止生成指令）
- 结果：生成图像完全消除目标元素，成功率100%
- 示例：“番茄田中的狗”→“普通田野中的狗”

### 案例2：RAG-Flow智能体集成
- 平台：可视化RAG工作流系统（商业级应用）
- 集成方式：嵌入本文RAG-based遗忘模块
- 核心指标：检索准确率96.2%，遗忘成功率95.3%，Agent适配率93.6%



<!-- 注：此处图片可替换为多模态遗忘结果对比图 -->

---

## 讨论与局限性

### 主要局限性
1. **自适应攻击风险**：若攻击者获取遗忘知识内容，USR可能降至20%（极端场景）
2. **检索算法依赖**：GPT-4o检索准确率100%，Contriever（97.6%）、Self-RAG（98.2%）效果稍弱
3. **知识库安全隐患**：遗忘知识项存在泄露风险，可能被恶意利用

### 针对性解决方案
1. 对抗自适应攻击：部署访问控制、Prompt清洗、对抗性检测三重防护
2. 降低检索依赖：融合语义匹配与关键词检索，提升开源检索器适配性
3. 强化知识库安全：对遗忘知识项加密存储，动态更新知识表示形式


